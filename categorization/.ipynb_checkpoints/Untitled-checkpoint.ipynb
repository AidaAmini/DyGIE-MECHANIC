{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f642df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.cluster import KMeans\n",
    "from joblib import dump, load\n",
    "\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed92fba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  # prediction path\n",
    "INPUT_SPAN_FILE_PATH = \"/data/edan/for_edan/cofie_spans.txt\"\n",
    "\n",
    "def embed_text(text, model):\n",
    "    input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)  # Batch size 1\n",
    "    input_ids = input_ids.to('cuda:1')\n",
    "    outputs = model(input_ids)\n",
    "    last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple\n",
    "    return last_hidden_states \n",
    "\n",
    "model_version = 'allenai/scibert_scivocab_uncased'\n",
    "do_lower_case = True\n",
    "model = BertModel.from_pretrained(model_version)\n",
    "model.to('cuda:1')\n",
    "tokenizer = BertTokenizer.from_pretrained(model_version, do_lower_case=do_lower_case)\n",
    "input_file = open(INPUT_SPAN_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dbd734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:1 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8083dfc9882f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_em_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mword_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_em_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-8083dfc9882f>\u001b[0m in \u001b[0;36mget_words\u001b[0;34m(input_file, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mword_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mword_em_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_em_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:1 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "def get_words(input_file, model):\n",
    "  word_list = []\n",
    "  word_em_list = []\n",
    "  count = 0\n",
    "  for line in input_file:\n",
    "    if count% 10000 == 0:\n",
    "      print(count)\n",
    "    # if count == 100000:\n",
    "    #   break\n",
    "    count += 1\n",
    "    if line[:-1] not in word_list:\n",
    "      word_list.append(line[:-1])\n",
    "      word_em_list.append(embed_text(word_list[-1], model).mean(1).detach().cpu().numpy()[0])\n",
    "  return word_list, word_em_list\n",
    "\n",
    "word_list, word_em_list = get_words(input_file, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b12ee5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.9454,  0.3655,  1.2571,  ...,  0.5111, -0.1379, -0.1853],\n",
       "         [-1.5300,  0.4414,  0.8334,  ...,  0.1994, -0.7094, -0.4333],\n",
       "         [-0.4388,  0.1096,  0.9537,  ...,  0.3195,  0.3462, -0.3863],\n",
       "         [-0.2652,  0.4500,  0.6051,  ...,  0.0814, -0.2493, -0.1242],\n",
       "         [-0.8609,  0.6019,  0.9810,  ...,  0.8701, -0.6452, -0.5931],\n",
       "         [-0.6354,  0.3130,  1.1275,  ...,  0.3738, -0.5448, -0.1816]]],\n",
       "       device='cuda:1', grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[ 2.5574e-01,  6.0404e-02,  1.8290e-01,  9.5414e-01,  3.2008e-01,\n",
       "          9.9996e-01,  4.7128e-01, -9.9972e-01,  3.5533e-01, -4.6941e-01,\n",
       "          4.9417e-01,  5.5816e-01,  9.9768e-01,  2.3358e-01, -1.8662e-01,\n",
       "          6.7355e-02, -1.8811e-01, -3.3453e-01,  9.0958e-01, -9.3147e-01,\n",
       "          9.8134e-03,  4.7100e-01,  9.8798e-01,  4.8994e-01, -9.9731e-01,\n",
       "          9.8753e-01, -8.2592e-01, -1.5636e-01, -9.3850e-02,  9.8496e-02,\n",
       "          3.8827e-01, -5.6767e-01,  4.9538e-01, -3.4446e-02, -2.6898e-02,\n",
       "          1.2901e-01,  9.9988e-01,  5.7903e-01,  3.1953e-01,  9.9433e-01,\n",
       "          2.6029e-02, -1.0667e-02, -8.9068e-01, -1.2880e-01,  3.8759e-01,\n",
       "          2.7527e-02, -1.5426e-01, -3.5308e-02,  3.4285e-01,  1.1452e-01,\n",
       "          6.3849e-01, -2.5853e-01, -8.2972e-02,  9.6959e-01,  9.9363e-01,\n",
       "         -8.0692e-02, -3.1733e-01,  4.0174e-01,  4.2383e-01,  9.4997e-01,\n",
       "         -1.6494e-01, -7.6098e-01,  3.7547e-01,  9.9718e-01,  2.1864e-01,\n",
       "         -1.7311e-02, -2.3444e-01, -3.7003e-01, -8.9935e-01,  3.0479e-01,\n",
       "          9.9937e-01, -1.4203e-01,  5.0417e-01, -9.9625e-01,  9.0675e-01,\n",
       "          9.1131e-02,  2.3462e-01, -2.7328e-01,  3.3931e-01,  9.2733e-02,\n",
       "          3.5930e-01, -2.2757e-01,  3.1802e-02, -9.9935e-01, -9.4055e-02,\n",
       "         -5.2962e-01, -1.4313e-01, -9.9651e-01,  9.9075e-01, -9.9042e-01,\n",
       "          7.8914e-01, -2.9358e-01, -3.3744e-01, -3.8635e-01, -4.8986e-01,\n",
       "          3.5111e-02, -3.2816e-02,  9.3889e-01,  4.6862e-01, -5.5982e-01,\n",
       "         -1.8664e-01, -1.2139e-01,  1.1283e-01,  1.1282e-01, -2.5411e-01,\n",
       "         -3.2211e-01, -3.3919e-03,  5.5762e-02, -2.3980e-01, -6.7760e-01,\n",
       "         -3.2272e-01, -6.4526e-02, -2.3803e-02, -3.3247e-01, -2.8935e-01,\n",
       "          3.4345e-01, -4.3702e-02,  4.9696e-02, -7.8905e-02, -1.0527e-01,\n",
       "          2.9886e-01,  6.5318e-01,  3.5075e-02, -2.9614e-01, -1.0938e-01,\n",
       "         -2.9438e-01, -8.6371e-02,  7.5025e-01,  4.2812e-01,  7.5268e-02,\n",
       "         -4.1469e-01,  5.2960e-01, -9.9780e-01, -1.3117e-01, -1.3026e-01,\n",
       "          1.9807e-01,  4.6070e-02, -2.3548e-01,  9.2061e-01, -2.6334e-01,\n",
       "         -2.0952e-01, -1.3266e-01, -5.1141e-02,  4.8654e-02,  9.7197e-01,\n",
       "         -3.8529e-01,  5.2574e-01,  1.7134e-01,  6.0281e-01,  5.9804e-01,\n",
       "          5.4845e-02,  1.2258e-01, -5.1315e-01,  9.9996e-01,  7.6799e-01,\n",
       "          6.9166e-01, -9.9471e-01,  9.9808e-01,  9.7927e-01,  6.6635e-01,\n",
       "          5.1027e-02,  2.1518e-01,  9.8939e-03, -4.5603e-01, -2.4594e-01,\n",
       "          2.2103e-01, -2.8079e-01,  9.0790e-01, -5.1527e-02, -9.9126e-01,\n",
       "         -1.5401e-01,  2.9175e-01, -2.2586e-01, -1.9437e-01, -9.9668e-01,\n",
       "          1.4487e-01, -9.9904e-01, -6.2998e-02,  5.4325e-01,  5.6903e-01,\n",
       "         -9.3672e-02,  8.4521e-01, -2.1902e-01,  1.2928e-01,  1.8270e-01,\n",
       "         -9.2752e-01, -3.6368e-01,  1.7625e-01, -2.8872e-01,  2.2550e-01,\n",
       "         -3.6185e-02,  4.1662e-01, -3.4206e-01,  5.8830e-01, -1.0000e+00,\n",
       "          6.2407e-01,  1.1075e-01, -4.1966e-01,  1.3557e-01,  2.9109e-01,\n",
       "         -3.4259e-02, -7.7649e-01,  9.5367e-03, -5.7261e-01,  2.7008e-01,\n",
       "          2.2254e-02,  8.9740e-01,  3.5877e-01, -9.9779e-01,  6.1596e-01,\n",
       "         -5.4702e-02, -9.9336e-01,  7.3325e-03,  6.2122e-01,  9.4018e-01,\n",
       "          1.0707e-01,  9.6622e-01, -9.4781e-01, -2.8538e-01, -2.6490e-01,\n",
       "          2.6643e-01,  5.3946e-01,  1.1959e-01,  9.9750e-01, -9.7567e-01,\n",
       "         -9.0991e-01,  4.8172e-02,  1.7973e-01, -1.2584e-01,  9.7888e-01,\n",
       "          1.1347e-01, -9.9862e-01,  1.2178e-01, -9.1682e-01, -3.2699e-01,\n",
       "          2.9551e-01,  1.2261e-01,  1.4564e-01, -2.0067e-02, -1.4584e-01,\n",
       "          2.0247e-01,  8.9242e-02, -2.5937e-02, -9.4355e-01,  1.1564e-02,\n",
       "          9.9943e-01,  2.0346e-01,  5.6147e-01, -7.9451e-01,  3.1017e-01,\n",
       "          5.1821e-01, -5.8800e-01,  8.7289e-02, -4.8053e-01,  1.8064e-02,\n",
       "         -4.4852e-01,  9.9658e-01,  6.3648e-01, -4.4355e-01, -4.1655e-01,\n",
       "         -4.1025e-02,  9.9640e-01,  9.3222e-01,  3.8150e-01, -9.9264e-01,\n",
       "         -4.7093e-02, -8.1775e-01,  7.8832e-01,  7.5061e-02, -9.7639e-01,\n",
       "         -5.4318e-02, -9.3605e-01, -2.1431e-01, -9.2968e-01, -8.9547e-02,\n",
       "          9.8392e-01, -2.6013e-02,  9.9429e-01,  4.2622e-01,  3.4239e-02,\n",
       "          3.0152e-01, -4.0069e-01,  3.1016e-01, -9.9731e-01,  1.8395e-01,\n",
       "         -1.8895e-01, -2.2308e-01, -9.9921e-01, -2.1890e-01,  4.4048e-01,\n",
       "          9.9974e-01,  7.7832e-01, -6.1659e-01, -9.9806e-01, -2.4089e-01,\n",
       "         -5.9402e-01, -9.9813e-01,  4.4778e-01, -8.8563e-01,  8.8384e-01,\n",
       "         -5.2059e-01,  9.6274e-01,  1.2112e-01, -9.9336e-01,  7.0879e-01,\n",
       "          1.8600e-01, -9.8653e-01, -3.5800e-01, -4.2005e-02, -9.8255e-01,\n",
       "         -9.9953e-01,  4.9864e-01, -2.4246e-01, -3.1436e-02, -4.5423e-01,\n",
       "          6.6192e-02, -1.4302e-01, -4.7126e-03,  9.9719e-01, -7.6295e-01,\n",
       "         -6.6817e-02, -3.7952e-01, -1.5861e-01,  1.1936e-02,  6.9288e-01,\n",
       "          3.0372e-01,  3.6480e-02, -9.5321e-01, -9.7372e-01, -9.9877e-01,\n",
       "         -1.1052e-02,  6.8106e-01, -3.2479e-01, -3.1047e-01, -3.9305e-01,\n",
       "         -3.2184e-01,  4.7087e-01,  1.5679e-01, -7.6309e-01,  1.0135e-02,\n",
       "         -3.0024e-01,  9.8968e-01, -1.7914e-01, -3.8795e-01,  1.8767e-01,\n",
       "          9.8581e-01, -2.8788e-01,  4.4629e-03, -3.6273e-01, -3.3375e-01,\n",
       "          1.0047e-01, -3.0384e-01,  9.8432e-01, -3.4767e-01,  7.2201e-02,\n",
       "         -3.2246e-01, -3.2692e-01, -6.5870e-01, -8.4010e-02, -2.6398e-01,\n",
       "         -1.5555e-01,  2.0265e-01, -5.8769e-02,  5.8062e-01, -9.9439e-01,\n",
       "          8.8487e-02, -6.9180e-01, -3.2047e-01,  3.7859e-01, -2.3801e-01,\n",
       "          2.1349e-01, -3.1740e-01,  1.4569e-01,  2.1546e-01,  9.9639e-01,\n",
       "          8.9223e-01, -2.9414e-01,  3.1612e-01,  1.4202e-01, -1.8959e-01,\n",
       "          3.1506e-01,  3.0143e-02, -5.1502e-01,  1.3891e-01,  9.9418e-01,\n",
       "         -7.1011e-02, -2.0845e-01, -2.9518e-01,  9.4586e-01,  7.9438e-01,\n",
       "          4.5499e-01,  1.8356e-01, -8.1292e-02, -1.9796e-01,  2.0629e-01,\n",
       "          7.6383e-02,  1.8069e-01,  9.8424e-01, -7.3668e-02,  3.8536e-01,\n",
       "         -9.9974e-01, -1.8371e-01, -1.9562e-01,  3.8880e-01, -3.6431e-01,\n",
       "         -1.3350e-02,  9.1435e-01, -9.9545e-01,  1.3720e-02, -1.2710e-01,\n",
       "          3.4462e-01,  3.3407e-01, -8.9938e-01, -5.1082e-01, -6.8268e-02,\n",
       "         -9.8675e-02,  8.0159e-02, -6.3841e-01, -5.1119e-01,  2.6984e-01,\n",
       "          3.0719e-01, -5.4387e-01, -2.9283e-01,  9.3388e-01, -2.6532e-01,\n",
       "         -4.4667e-01, -4.3987e-01,  1.7743e-01,  1.2577e-01,  3.0951e-01,\n",
       "          5.5405e-01,  9.7369e-01, -3.0474e-01,  9.9674e-01,  8.5474e-01,\n",
       "          1.3251e-01, -1.9996e-01, -9.6189e-02, -4.0717e-01,  6.1095e-01,\n",
       "          3.2292e-02, -1.5277e-01, -7.0281e-01,  9.9877e-01, -1.3576e-01,\n",
       "          2.2738e-01, -9.8825e-01,  4.2855e-01, -9.9012e-01, -4.6475e-01,\n",
       "         -5.5633e-01, -2.0274e-01,  1.7581e-01,  5.1784e-01, -6.1733e-01,\n",
       "         -1.7033e-01, -2.2295e-01, -9.0490e-01,  4.0214e-02,  2.1686e-01,\n",
       "          9.5066e-02, -4.3292e-02,  2.7947e-01,  9.9398e-01, -1.9792e-01,\n",
       "         -8.8424e-01, -6.1079e-02, -5.0542e-01, -2.2116e-01,  9.7845e-01,\n",
       "         -1.5351e-01, -1.9133e-03,  7.6710e-01, -7.4045e-02,  6.3338e-01,\n",
       "         -3.9491e-01,  9.6844e-01, -1.3895e-01,  3.2967e-01, -1.0284e-01,\n",
       "         -2.5697e-01, -9.3007e-02, -1.6929e-01, -2.9073e-01,  4.4910e-01,\n",
       "         -2.4209e-02, -4.4421e-01, -2.5646e-01, -1.7315e-01,  1.8690e-01,\n",
       "          1.4766e-01,  2.2150e-01, -2.9798e-01,  2.6486e-01, -8.0535e-01,\n",
       "          3.1470e-01, -9.8814e-01,  3.1635e-02,  9.9746e-01,  5.5410e-01,\n",
       "         -9.7647e-01, -9.4396e-01,  1.7912e-02, -4.8265e-02, -4.5184e-01,\n",
       "         -9.0086e-01, -9.8756e-01, -4.0483e-01,  9.9925e-01, -2.7737e-01,\n",
       "          5.3748e-01, -1.8936e-01,  9.9228e-01,  4.0501e-01, -2.2159e-01,\n",
       "         -6.0670e-01,  2.6177e-01,  9.9474e-01,  2.7827e-01, -2.1433e-01,\n",
       "         -2.4742e-01,  5.0578e-02,  9.9808e-01,  9.9637e-01, -4.4905e-01,\n",
       "         -2.5320e-01, -2.3636e-01,  9.9997e-01,  5.7265e-01, -1.4827e-01,\n",
       "          8.4465e-02, -3.3963e-01, -6.2583e-02,  2.9608e-01, -4.3356e-01,\n",
       "          1.7849e-01,  3.7640e-01,  9.8112e-01, -8.9701e-01, -4.1557e-01,\n",
       "          2.8436e-01, -8.2300e-01,  2.4870e-01, -5.1329e-01, -2.8520e-01,\n",
       "         -2.2517e-01, -9.8889e-01, -9.2548e-01,  2.5669e-02,  3.1298e-01,\n",
       "         -1.2150e-01, -3.3213e-01, -3.3759e-01,  7.2552e-01, -8.3014e-01,\n",
       "         -1.9299e-01,  6.0829e-02,  3.5492e-01,  2.8248e-01, -5.5370e-01,\n",
       "         -3.2443e-01, -1.4169e-01,  9.8784e-01,  3.4224e-01,  9.9967e-01,\n",
       "          2.2392e-01, -9.9291e-01,  9.9872e-01, -5.2025e-01,  4.3054e-02,\n",
       "         -4.6716e-01,  5.3019e-01,  2.4127e-01, -2.0044e-01,  8.1076e-01,\n",
       "         -3.4499e-01,  1.8398e-01,  9.6967e-01,  2.2034e-01, -2.0012e-01,\n",
       "          8.9903e-01,  9.9970e-01,  9.9842e-01, -9.8540e-01,  3.4287e-01,\n",
       "          8.9719e-01, -2.3437e-01,  6.6338e-03,  9.9400e-01,  8.9582e-02,\n",
       "          1.3200e-01,  8.5038e-01,  9.7803e-01, -3.7683e-02,  8.8100e-02,\n",
       "         -9.7719e-01,  2.4427e-02,  6.7876e-01, -4.2015e-01, -5.5764e-02,\n",
       "          2.4724e-02,  1.0434e-01, -6.0245e-01, -5.2434e-01, -1.4973e-01,\n",
       "          9.8839e-01,  3.0498e-01, -4.8575e-01, -2.1277e-01,  5.4739e-01,\n",
       "         -9.9677e-01, -4.5183e-01,  1.5342e-01, -1.6848e-01, -1.9365e-01,\n",
       "          2.3494e-01, -5.1266e-01, -1.0158e-01,  9.1682e-01, -8.6274e-02,\n",
       "          1.5850e-01,  2.5470e-02, -4.9560e-01, -1.9421e-01, -7.2292e-02,\n",
       "         -2.7613e-01,  9.3446e-01, -9.9836e-01,  8.2244e-02,  9.9916e-01,\n",
       "         -9.9931e-01,  5.2565e-02, -1.1556e-01,  6.1260e-02,  4.6228e-02,\n",
       "          4.7551e-01, -9.1512e-01, -9.6020e-02,  6.3073e-02, -9.7086e-01,\n",
       "         -3.8768e-01, -9.9981e-01,  5.1291e-01, -2.0918e-03,  1.9695e-01,\n",
       "          8.2938e-01,  4.6194e-01, -2.2019e-02,  8.9952e-01, -3.2576e-01,\n",
       "         -1.2739e-01,  6.4489e-04,  5.0741e-01, -1.3277e-01, -2.7800e-02,\n",
       "         -8.6670e-02, -3.9369e-01, -6.1551e-02,  1.7035e-01, -9.8645e-01,\n",
       "         -8.8946e-01,  1.9533e-02,  3.3311e-01, -7.5639e-01,  2.1307e-01,\n",
       "          9.1623e-01, -1.8433e-01, -8.9480e-01, -3.5574e-01, -3.9903e-01,\n",
       "         -5.4264e-01,  9.9370e-01, -1.0553e-01, -3.1964e-01,  3.1700e-01,\n",
       "          9.6207e-01, -9.8814e-01, -2.8376e-01, -1.8016e-01, -7.9536e-01,\n",
       "         -5.6203e-01,  4.5096e-01,  4.7255e-01,  6.0807e-02,  9.5865e-01,\n",
       "         -2.7393e-01, -9.4129e-01,  1.8066e-01,  5.4754e-01, -9.9836e-01,\n",
       "          3.3966e-01,  3.7322e-01,  1.8699e-01, -1.2450e-01,  1.7762e-01,\n",
       "         -1.8029e-01, -4.3622e-01, -1.4133e-01, -2.4379e-01,  7.7438e-02,\n",
       "          4.1440e-01,  9.9969e-01, -9.1301e-01,  9.6480e-01,  3.9523e-02,\n",
       "          1.2067e-01, -2.4787e-01, -2.0968e-01, -7.0531e-01, -9.7065e-02,\n",
       "         -4.1426e-01,  6.8136e-02,  3.1057e-01, -1.5951e-02, -2.1237e-01,\n",
       "          2.5880e-01, -9.9547e-01, -2.4793e-01, -7.5833e-01, -9.9884e-01,\n",
       "         -1.5685e-01, -4.2049e-02,  9.4584e-01,  5.9816e-03, -7.6571e-01,\n",
       "         -9.5348e-01,  1.2092e-02,  5.7313e-02, -3.3237e-01, -9.2315e-01,\n",
       "         -5.3423e-01,  5.2390e-01,  9.7004e-01,  1.2882e-02,  9.9786e-01,\n",
       "          9.9593e-01,  1.5035e-02, -4.0929e-01, -2.2151e-01,  9.9462e-01,\n",
       "          1.9715e-01,  9.9379e-01, -1.6507e-01,  8.6937e-01, -3.0124e-02,\n",
       "          9.9239e-01,  5.5741e-01,  6.7011e-02, -2.6172e-01,  9.9635e-01,\n",
       "         -9.4832e-01,  5.0873e-01,  3.6339e-01, -9.8818e-01, -3.4112e-01,\n",
       "          1.4890e-01, -4.2344e-01,  9.8541e-01, -4.4774e-01, -4.9395e-01,\n",
       "          6.8625e-02,  1.4561e-01,  1.7111e-01,  6.8823e-02, -2.5223e-01,\n",
       "         -1.3783e-02,  9.2035e-01,  3.0841e-01]], device='cuda:1',\n",
       "       grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c864dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = load(\"training_kmeans.joblib\")\n",
    "predictions = kmeans.predict(word_em_list)\n",
    "output_file = open(\"k_means_clusters_predict.tsv\", \"w\")\n",
    "for i in predictions:\n",
    "print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
